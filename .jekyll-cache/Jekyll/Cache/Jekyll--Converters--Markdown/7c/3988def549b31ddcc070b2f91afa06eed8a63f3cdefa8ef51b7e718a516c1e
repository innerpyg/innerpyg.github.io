I"è6<h2 id="yolo-v4--optimal-speed-and-accuracy-of-objefct-detection">YOLO v4 : Optimal Speed and Accuracy of Objefct Detection.</h2>

<p><br /></p>

<h4 id="reference">Reference</h4>

<p><a href="https://arxiv.org/pdf/2004.10934v1.pdf">YOLO v4 Paper</a></p>

<p><br /></p>

<h4 id="abstract">Abstract</h4>

<ul>
  <li>CNN ì •í™•ë„ ê°œì„ ì„ ìœ„í•œ ìˆ˜ë§ì€ feature(function)ë“¤ì´ ì¡´ì¬</li>
  <li>ì–´ë–¤ featureë“¤ì€ íŠ¹ì • model or problemì—ë§Œ êµ­í•œë˜ì–´ ë™ì‘í•˜ê±°ë‚˜ ì†Œê·œëª¨ ë°ì´í„°ì…‹ì— ëŒ€í•´ì„œë§Œ ë™ì‘í•˜ëŠ” ê²ƒë“¤ì´ ìˆìŒ</li>
  <li>ë°˜ë©´ì— ëŒ€ë¶€ë¶„ì˜ model ë“±ì— ì ìš© ê°€ëŠ¥í•œ universal í•œ featureë“¤ì´ ì¡´ì¬í•¨
    <ul>
      <li>Weighted-Residual-Connections(WRC)</li>
      <li>Cross-Stage-Partial-connections(CSP)</li>
      <li>Cross mini-Batch Normalization (CmBN)</li>
      <li>Self-adversarial-training(SAT)</li>
      <li>Mish-activation</li>
    </ul>
  </li>
  <li>ì´ ë…¼ë¬¸ì—ì„œëŠ” ì•„ë˜ì˜ ë‚´ìš©ì— ë”°ë¼ ë¶„ì„ì„ ì§„í–‰í•¨.
    <ul>
      <li>WRC, CSP, CmBN, SAT, Mish-activation, Mosaic data augmentation, DropBlock regularization, CIoUë¥¼ ì¡°í•©í•˜ì—¬ SOTA ë‹¬ì„±.</li>
      <li>MS COCO data ê¸°ì¤€ 43.5% AP(65.6% AP<sub>50</sub>)</li>
      <li>Tesla V100 ê¸°ì¤€ ~ 65FPS</li>
    </ul>
  </li>
</ul>

<p><br /></p>

<p><strong>YOLO v4</strong></p>
<ul>
  <li>CSPDarknet53</li>
  <li>SPP + PAN</li>
  <li>YOLO v3</li>
  <li>Many BoF + Bos feautres</li>
</ul>

<hr />

<p><br /></p>

<h4 id="intro">Intro</h4>

<ul>
  <li>ëŒ€ë¶€ë¶„ì˜ CNN ê¸°ë°˜ object detectionì—ëŠ” ì •í™•ë„ì™€ ì†ë„ ê°„ trade-offê°€ ì¡´ì¬
    <ul>
      <li>ì£¼ì°¨ ê°€ëŠ¥ ê³µê°„ íƒìƒ‰ : ëŠë¦¬ì§€ë§Œ ì •í™•í•œ Model</li>
      <li>ì°¨ëŸ‰ ì¶”ëŒ ê²½ê³  : ë¹ ë¥´ì§€ë§Œ ë¶€ì •í™•í•œ Model</li>
    </ul>
  </li>
  <li>ë³¸ ë…¼ë¬¸ì˜ ëª©ì 
    <ul>
      <li>ëˆ„êµ¬ë‚˜ ì‹¤ì‹œê°„/ê³ í’ˆì§ˆì˜ ê²°ê³¼ë¥¼ ì–»ì„ ìˆ˜ ìˆë„ë¡</li>
      <li>BFLOP ì¦‰, ì—°ì‚°ì„ ì¤„ì´ëŠ” ê²Œ ì•„ë‹ˆë¼ ìƒì‚°í•˜ëŠ” ë‹¨ê³„ì—ì„œ ë¹ ë¥¸ ì†ë„ë¡œ ë™ì‘í•˜ëŠ” object detector ê³ ì•ˆí•˜ê³  ë³‘ë ¬ ìµœì í™”</li>
    </ul>
  </li>
</ul>

<p><img src="/assets/images/CV/YOLOv4_Paper-2.png" width="500" height="400" /></p>

<ul>
  <li>ë³¸ ë…¼ë¬¸ì˜ ê²°ê³¼ ê¸°ì—¬
    <ul>
      <li>ë³´ë‹¤ ê°•ë ¥í•œ Object detector ê°œë°œ</li>
      <li>ìµœì‹  Bag-of-freebies, Bag-of-Specials ê¸°ë²• íš¨ê³¼ ê²€ì¦</li>
      <li>ë‹¨ì¼ GPUì— íš¨ìœ¨ì ìœ¼ë¡œ ì í•©í•˜ê¸° ìœ„í•œ ìµœì‹  ê¸°ë²•ë“¤ì„ ìˆ˜ì •
        <ul>
          <li>CBN</li>
          <li>PAN</li>
          <li>SAM</li>
          <li>etc..</li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<p><br /></p>

<h4 id="related-work">Related work</h4>

<ul>
  <li>Object Detection model
    <ol>
      <li>Backbone : ImageNetì„ ì´ìš©í•œ pre-trained
        <ul>
          <li>GPU ê¸°ë°˜ : VGG, ResNet, ResNeXt, DenseNet, etc</li>
          <li>CPU ê¸°ë°˜ : SqueezeMet. MobileNet, ShuffleNet, etc</li>
        </ul>
      </li>
      <li>Head : classì™€ BBox predictionì— ì ìš©
        <ul>
          <li>one-stage detector
            <ul>
              <li>anchor-based : YOLO, SSD, RetinaNet, etc</li>
              <li>anchor-free : CenterNet, CornetNet, FCOS, etc</li>
            </ul>
          </li>
          <li>two-stage detector
            <ul>
              <li>anchor-based : R-CNN series, etc</li>
              <li>anchor-free : RedPoints, etc</li>
            </ul>
          </li>
        </ul>
      </li>
      <li>Neck : backboneê³¼ head ì‚¬ì´ì— í¬ê³  ì‘ì€ object detectionê°€ ê°€ëŠ¥í•˜ë„ë¡  ì—¬ëŸ¬ feature mapì˜ íŠ¹ì„±ì„ ëª¨ìœ¼ëŠ” ì—­í• 
        <ul>
          <li>Feature Pyramid Network(FPN), Path Aggregation Network(PAN), BiFPN, NAS-FPN, etc</li>
        </ul>
      </li>
      <li>Others : ìƒˆë¡­ê²Œ ì—°êµ¬ ëœ ë¶€ë¶„
        <ul>
          <li>ìƒˆë¡œìš´ backbone : DetNet, DetNAS, etc</li>
          <li>ìƒˆë¡œìš´ ëª¨ë¸ êµ¬ì¶• : SpineNet, HitDetector, etc</li>
        </ul>
      </li>
    </ol>
  </li>
</ul>

<p><br /></p>

<p><strong>ì¼ë°˜ì ì¸ object detection êµ¬ì¡°</strong></p>

<p><img src="/assets/images/CV/YOLOv4_Paper-1.png" alt="" /></p>

<p><br /></p>

<ul>
  <li>
    <p>Bag of Freebies(BoF)</p>

    <ol>
      <li>data augmentation
        <ul>
          <li>inputì˜ ê°€ë³€ì„±ì„ ì¦ê°€ì‹œì¼œ modelì´ ë‹¤ë¥¸ í™˜ê²½ì—ì„œ ì–»ì€ ì´ë¯¸ì§€(resolution ë“± quality ì°¨ì´ê°€ ìˆëŠ”)ì— ëŒ€í•´ì„œë„ ë†’ì€ ê°•ê±´í•¨ì„ ìœ ì§€í•˜ëŠ” ê²ƒì´ ëª©ì </li>
        </ul>
        <ul>
          <li>ê´‘í•™ì , ê¸°í•˜í•™ì , pixel-wise</li>
          <li>object occlusion ë¬¸ì œì— ì¤‘ì ì„ ì—°êµ¬</li>
          <li>ì—¬ëŸ¬ ì´ë¯¸ì§€ë¥¼ í•¨ê»˜ ì‚¬ìš©í•˜ëŠ” ë°©ë²•</li>
          <li>style transfer GAN ì ìš©í•˜ì—¬ texture biasë¥¼ íš¨ê³¼ì ìœ¼ë¡œ ì¤„ì„.</li>
        </ul>
      </li>
      <li>regularization
        <ul>
          <li>data augmentationê³¼ ìœ ì‚¬í•œ ê°œë…ì„ feature mapì— ì ìš©í•˜ëŠ” ì—°êµ¬</li>
        </ul>
      </li>
      <li>imbalance sampling
        <ul>
          <li>class imbalance</li>
          <li>ì„œë¡œ ë‹¤ë¥¸ category ê°„ ì—°ê´€ì„±ì„ í‘œí˜„í•˜ê¸° ì–´ë ¤ìš´ ë¶€ë¶„ì— ëŒ€í•œ ì—°êµ¬</li>
        </ul>
      </li>
      <li>objective function(BBox regression) - <a href="">IoU description page. to be update</a>
        <ul>
          <li>IoU loss</li>
          <li>GIoU loss</li>
          <li>DIoU, CIoU loss</li>
        </ul>
      </li>
    </ol>
  </li>
</ul>

<p><br /></p>

<ul>
  <li>
    <p>Bag of Specials(BoS)</p>

    <ol>
      <li>plugin modules
        <ul>
          <li>receptive field enhancement module
            <ul>
              <li>SPP</li>
              <li>ASPP</li>
              <li>REB</li>
            </ul>
          </li>
          <li>attention modules
            <ul>
              <li>Squeeze-and-Excitation(SE)</li>
              <li>Spatial Attention Module(SAM)</li>
            </ul>
          </li>
          <li>feature integration
            <ul>
              <li>FPN ë“±</li>
            </ul>
          </li>
          <li>activation function : gradient vanish ë¬¸ì œ í•´ê²°í•˜ê¸° ìœ„í•´
            <ul>
              <li>ReLU</li>
              <li>LReLU, PReLU : ReLUì˜ ì¶œë ¥ì´ 0ë³´ë‹¤ ì‘ì„ ê²½ìš° gradientê°€ 0ì´ ë˜ëŠ” ë¬¸ì œë¥¼ í•´ê²°</li>
              <li>ReLU6, hard-Swish : quantization networksë¥¼ ê³ ë ¤</li>
              <li>SELU : neural networkë¥¼ self-normalizingí•˜ê¸° ìœ„í•œ ëª©ì </li>
              <li>Swish, Mish : continuously differentiable activation function</li>
            </ul>
          </li>
        </ul>
      </li>
    </ol>
  </li>
</ul>

<p><br /></p>

<ol>
  <li>post-processing : ì¼ë°˜ì ìœ¼ë¡œ NMS(Non-Maximum Suppression)
    <ul>
      <li>NMS</li>
      <li>greedy NMS</li>
      <li>soft NMS, DIoU
        <h6 id="-anchor-free-ê¸°ë²•ì—ì„œëŠ”-post-processingì´-í•„ìš”í•˜ì§€-ì•ŠìŒ">&gt; anchor-free ê¸°ë²•ì—ì„œëŠ” post-processingì´ í•„ìš”í•˜ì§€ ì•ŠìŒ.</h6>
      </li>
    </ul>
  </li>
</ol>

<p><br /></p>

<h4 id="methodology">Methodology</h4>

<p><br /></p>

<ol>
  <li>Selection of architecture
    <ul>
      <li>detector ì„ íƒ ì‹œ ê³ ë ¤ ì‚¬í•­
        <ul>
          <li>ë” í° í¬ê¸°ì˜ input resolution</li>
          <li>ë”ë§ì€ layer ìˆ˜ &gt; ë” í° receptive field</li>
          <li>ë” ë§ì€ parameter ìˆ˜ : ì„œë¡œ ë‹¤ë¥¸ í¬ê¸°ì˜ objectsë“¤ì„ ê²€ì¶œí•˜ê¸° ìœ„í•´</li>
        </ul>
      </li>
      <li>CSPDarknet53ì— SPP block ì¶”ê°€
        <ul>
          <li>receptive field í–¥ìƒ</li>
          <li>context features ë¶„ë¦¬</li>
          <li>network ì†ë„ ì €í•˜ ì—†ìŒ</li>
        </ul>
      </li>
      <li>CPSDarknet53ì— parameter aggregation ê¸°ë²•ìœ¼ë¡œ PAN ì´ìš©</li>
    </ul>
  </li>
</ol>

<p><img src="/assets/images/CV/YOLOv4_Paper-3.png" alt="" /></p>

<p><br /></p>

<blockquote>
  <p>ìµœì¢…ì ìœ¼ë¡œ ì„ íƒëœ ê¸°ë²•ë“¤ <br />
  backbone : CSPDarknet53 <br />
  neck <br />
    - additional blocks : SPP <br />
    - path-aggregation blocks : PANet <br />
  head : YOLO v3(anchor-based)</p>
</blockquote>

<p><br /></p>

<ol>
  <li>Selection of BoF and BoS
    <ul>
      <li>BoF í›„ë³´ features</li>
    </ul>
    <ul>
      <li>BBox regression : MSE, IoU, GIoU, DIoU, CIoU</li>
      <li>data augmentation : CutOut, MixUp, CutMix</li>
      <li>
        <p>regulation method : <del>DropOut, DropPath, Spatial DropOut</del>, DropBlock</p>

        <h6 id="-dropblockì„-ê²Œì‹œí•œ-ì‚¬ëŒë“¤ì´-ë‹¤ë¥¸-ì •ê·œí™”-ë°©ë²•ê³¼-ë¹„êµí–ˆì„-ë•Œ-ìš°ìˆ˜í•œ-ì„±ëŠ¥ì„-ë³´ì„ì„-ì…ì¦">&gt; DropBlockì„ ê²Œì‹œí•œ ì‚¬ëŒë“¤ì´ ë‹¤ë¥¸ ì •ê·œí™” ë°©ë²•ê³¼ ë¹„êµí–ˆì„ ë•Œ ìš°ìˆ˜í•œ ì„±ëŠ¥ì„ ë³´ì„ì„ ì…ì¦</h6>
      </li>
    </ul>
  </li>
</ol>

<ul>
  <li>BoS í›„ë³´ features
    <ul>
      <li>activations : ReLU, leaky-ReLU, <del>parametric ReLU, ReLU6, SELU</del>, Swish, Mish</li>
      <li>normalization of the network activations
        <ul>
          <li>Batch Normalization</li>
          <li><del>Cross GPU batch Normalization(CGBN or SyncBN)</del> : ë³¸ ì—°êµ¬ëŠ” í•˜ë‚˜ì˜ GPUë¥¼ ì´ìš©í•˜ëŠ” ê²ƒì´ ì¤‘ì ì´ê¸° ë•Œë¬¸ì— ì œì™¸</li>
          <li>Filter Response Normalization</li>
          <li>Cross-iteration Batch Normalization</li>
        </ul>
      </li>
      <li>skip-connections
        <ul>
          <li>Residual connections</li>
          <li>Weighted residual connections</li>
          <li>Multi-input weighted residual connections</li>
          <li>Cross stage partial connections(CSP)</li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<p><br /></p>

<ol>
  <li>Additional improvements
    <ul>
      <li>ìƒˆë¡­ê²Œ ë„ì…í•œ BoF data augmentation</li>
    </ul>
    <ul>
      <li>Mosaic
        <ul>
          <li>4ê°œì˜ train imageë¥¼ 1ê°œë¡œ mix</li>
          <li>
            <p>batch normalizationì€ ê° layer ìƒì—ì„œ ì„œë¡œ ë‹¤ë¥¸ 4ê°œì˜ ì´ë¯¸ì§€ë“¤ì— ëŒ€í•œ activation statistic ê³„ì‚° ê°€ëŠ¥</p>

            <h6 id="-í°-í¬ê¸°ì˜-mini-batchì—-ëŒ€í•œ-í•„ìš”ì„±ì„-ì¤„ì¼-ìˆ˜-ìˆìŒ">&gt; í° í¬ê¸°ì˜ mini-batchì— ëŒ€í•œ í•„ìš”ì„±ì„ ì¤„ì¼ ìˆ˜ ìˆìŒ.</h6>
            <p><img src="/assets/images/CV/YOLOv4_Paper-4.png" width="500" height="400" /></p>
          </li>
        </ul>
      </li>
      <li>SAT(Self-Adversarial Training)
        <ul>
          <li>2ë‹¨ê³„ì˜ forward &amp; backward ë‹¨ê³„ë¡œ ë™ì‘</li>
          <li>
            <p>1ë‹¨ê³„ : networkì˜ weightê°€ ì•„ë‹Œ ì›ë³¸ ì´ë¯¸ì§€ë¥¼ ë³€ê²½</p>

            <h6 id="-ìì²´ì ìœ¼ë¡œ-adversarial-attackì„-ìˆ˜í–‰-ì´ë¯¸ì§€ì—-ì›í•˜ëŠ”-objectê°€-ì—†ë‹¤ëŠ”-ì†ì„ìˆ˜ë¥¼-ë§Œë“¤ë„ë¡-ì›ë³¸-ì´ë¯¸ì§€ë¥¼-ë³€ê²½">&gt; ìì²´ì ìœ¼ë¡œ adversarial attackì„ ìˆ˜í–‰, ì´ë¯¸ì§€ì— ì›í•˜ëŠ” objectê°€ ì—†ë‹¤ëŠ” ì†ì„ìˆ˜ë¥¼ ë§Œë“¤ë„ë¡ ì›ë³¸ ì´ë¯¸ì§€ë¥¼ ë³€ê²½</h6>
          </li>
          <li>2ë‹¨ê³„ : ë³€ê²½ëœ ì´ë¯¸ì§€ì— ëŒ€í•´ ì •ìƒì ì¸ ë°©ì‹ì˜ object detectí•˜ë„ë¡ training
    - BoS</li>
        </ul>
      </li>
      <li>CmBN
        <ul>
          <li>CBNì˜ ë³€ê²½ëœ ë²„ì „, ë‹¨ì¼ batch ë‚´ì—ì„œ mini-batches ê°„ statistic ìˆ˜ì§‘</li>
          <li>BNì€ batch sizeê°€ ì‘ì„ ê²½ìš° examplesì— ëŒ€í•´ ì •í™•í•œ statistic estimationì´ ì–´ë ¤ì›€
            <h6 id="-cbnì€-ì´ì „-iterationë“¤ì˜-statisticì„-í•¨ê»˜-í™œìš©">&gt; CBNì€ ì´ì „ iterationë“¤ì˜ statisticì„ í•¨ê»˜ í™œìš©</h6>
            <p><img src="/assets/images/CV/YOLOv4_Paper-5.png" width="500" height="350" />
<br /><br /></p>
          </li>
        </ul>
      </li>
      <li>modified SAM(Spatial Attention Module), modified PAN(Path Aggregation Network)
        <ul>
          <li>SAMì„ spatial-wise &gt; point-wiseë¡œ ë³€ê²½</li>
          <li>PANì˜ shortcut connection &gt; concatenationìœ¼ë¡œ</li>
        </ul>

        <p><img src="/assets/images/CV/YOLOv4_Paper-6.png" width="500" height="450" /></p>
      </li>
    </ul>
  </li>
</ol>

<p><br /></p>

<hr />

<p><strong>4. YOLO v4 architecture</strong></p>

<ul>
  <li>CSPDarknet53</li>
  <li>SPP + PAN</li>
  <li>YOLO v3</li>
  <li>
    <p>Many BoF + Bos feautres</p>
  </li>
  <li>BoF</li>
  <li>for backbone
    <ul>
      <li>data augmentation : CutMix, Mosaic</li>
      <li>imbalance sampling : Class labeling smoothing</li>
      <li>regularization : DropBlock</li>
    </ul>
  </li>
  <li>for detector
    <ul>
      <li>object function : CIoU loss</li>
      <li>normalization of network activation : CmBN</li>
      <li>regularization : DropBlock</li>
      <li>data augmentation : Mosic, Self-Adversarial Training(SAT)</li>
      <li>hyper-parameters optimization : Genetic algorithms</li>
      <li>learning rate scheduler : Cosine annealing scheduler</li>
      <li>others
        <ul>
          <li>Eliminate grid sensitivity</li>
          <li>Using multiple anchors for a single ground truth</li>
          <li>Random training Shapes.</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>BoS
    <ul>
      <li>for backbone
        <ul>
          <li>activation function : Mish</li>
          <li>skep-connection : CSP, MiWRC</li>
        </ul>
      </li>
      <li>for detector
        <ul>
          <li>activation function : Mish</li>
          <li>receptive field enhancement : SPP</li>
          <li>attention : SAM</li>
          <li>feature integration : PAN</li>
          <li>post-processing : DIoU NMS</li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<p><br /><br /></p>

<p><strong>ìš©ì–´ ì •ë¦¬</strong></p>

<ul>
  <li>ASFF : Adaptively Spatial Feature Fusion</li>
  <li>ASPP : Atrous Spatial Pyramid Pooling</li>
  <li>BiFPN : Bidirectional Feature Pyramid Network</li>
  <li>CBN : Cross-iteration Batch Normalization</li>
  <li>CmBN : Cross mini-Batch Normalization</li>
  <li>CSP : Cross-Stage-Partial-connections</li>
  <li>FCOS : Fully Convolutional One-Stage pbject detector</li>
  <li>MiWRC : Multi-input-Weighted-Residual-Connections</li>
  <li>NAS-FPN : Neural Architecture Search Feature Pyramid Network</li>
  <li>PAN : Path Aggregation Network</li>
  <li>RFB : Receptive Field Block</li>
  <li>SAM : Spatial Attention Module</li>
  <li>SAT : Self-Adversarial-Training</li>
  <li>SE : Squeeze-and-Exitation</li>
  <li>SFAM : Scale-wise-Feature-Aggregation Module</li>
  <li>SPP : Spatial Pyramid Pooling</li>
</ul>
:ET